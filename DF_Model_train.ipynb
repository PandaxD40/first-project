{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOgwSXSeSKByQ+p62LIihfP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PandaxD40/first-project/blob/main/DF_Model_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0GTRLGDWcOT",
        "outputId": "d82fba19-a689-4565-c19c-9619358dadd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install face_recognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ETQHDjLWzN4",
        "outputId": "bfc5b3e2-1ebd-4bd9-e631-e6356110e8b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.7)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (10.4.0)\n",
            "Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566164 sha256=2cbfbaf1fcb7e151de145f8017cf447acaf26e0dd6bfcdd844a3fe31f1f5305a\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face_recognition\n",
            "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#THis code is to check if the video is corrupted or not..\n",
        "#If the video is corrupted delete the video.\n",
        "import glob\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import face_recognition\n",
        "#Check if the file is corrupted or not\n",
        "def validate_video(vid_path,train_transforms):\n",
        "      transform = train_transforms\n",
        "      count = 20\n",
        "      video_path = vid_path\n",
        "      frames = []\n",
        "      a = int(100/count)\n",
        "      first_frame = np.random.randint(0,a)\n",
        "      temp_video = video_path.split('/')[-1]\n",
        "      for i,frame in enumerate(frame_extract(video_path)):\n",
        "        frames.append(transform(frame))\n",
        "        if(len(frames) == count):\n",
        "          break\n",
        "      frames = torch.stack(frames)\n",
        "      frames = frames[:count]\n",
        "      return frames\n",
        "#extract a from from video\n",
        "def frame_extract(path):\n",
        "  vidObj = cv2.VideoCapture(path)\n",
        "  success = 1\n",
        "  while success:\n",
        "    success, image = vidObj.read()\n",
        "    if success:\n",
        "          yield image\n",
        "\n",
        "im_size = 112\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "                                        transforms.ToPILImage(),\n",
        "                                        transforms.Resize((im_size,im_size)),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean,std)])\n",
        "video_fil =  glob.glob('/content/drive/MyDrive/Face_only_data/*.mp4')\n",
        "print(\"Total no of videos :\" , len(video_fil))\n",
        "print(video_fil)\n",
        "count = 0;\n",
        "for i in video_fil:\n",
        "  try:\n",
        "    count+=1\n",
        "    validate_video(i,train_transforms)\n",
        "  except:\n",
        "    print(\"Number of video processed: \" , count ,\" Remaining : \" , (len(video_fil) - count))\n",
        "    print(\"Corrupted video is : \" , i)\n",
        "    continue\n",
        "print((len(video_fil) - count))"
      ],
      "metadata": {
        "id": "HTw-UShOivKc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8289dfdd-aebd-4014-dd6c-726be14f6d77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total no of videos : 376\n",
            "['/content/drive/MyDrive/Face_only_data/aapnvogymq.mp4', '/content/drive/MyDrive/Face_only_data/abarnvbtwb.mp4', '/content/drive/MyDrive/Face_only_data/aagfhgtpmv.mp4', '/content/drive/MyDrive/Face_only_data/acxwigylke.mp4', '/content/drive/MyDrive/Face_only_data/acifjvzvpm.mp4', '/content/drive/MyDrive/Face_only_data/abqwwspghj.mp4', '/content/drive/MyDrive/Face_only_data/aczrgyricp.mp4', '/content/drive/MyDrive/Face_only_data/adohikbdaz.mp4', '/content/drive/MyDrive/Face_only_data/acxnxvbsxk.mp4', '/content/drive/MyDrive/Face_only_data/acqfdwsrhi.mp4', '/content/drive/MyDrive/Face_only_data/aelzhcnwgf.mp4', '/content/drive/MyDrive/Face_only_data/aelfnikyqj.mp4', '/content/drive/MyDrive/Face_only_data/afoovlsmtx.mp4', '/content/drive/MyDrive/Face_only_data/adylbeequz.mp4', '/content/drive/MyDrive/Face_only_data/agqphdxmwt.mp4', '/content/drive/MyDrive/Face_only_data/aettqgevhz.mp4', '/content/drive/MyDrive/Face_only_data/agrmhtjdlk.mp4', '/content/drive/MyDrive/Face_only_data/ahbweevwpv.mp4', '/content/drive/MyDrive/Face_only_data/aevrfsexku.mp4', '/content/drive/MyDrive/Face_only_data/ahqqqilsxt.mp4', '/content/drive/MyDrive/Face_only_data/aklqzsddfl.mp4', '/content/drive/MyDrive/Face_only_data/ahdbuwqxit.mp4', '/content/drive/MyDrive/Face_only_data/ahfazfbntc.mp4', '/content/drive/MyDrive/Face_only_data/aknbdpmgua.mp4', '/content/drive/MyDrive/Face_only_data/ajqslcypsw.mp4', '/content/drive/MyDrive/Face_only_data/ajwpjhrbcv.mp4', '/content/drive/MyDrive/Face_only_data/aipfdnwpoo.mp4', '/content/drive/MyDrive/Face_only_data/akvmwkdyuv.mp4', '/content/drive/MyDrive/Face_only_data/amaivqofda.mp4', '/content/drive/MyDrive/Face_only_data/aladcziidp.mp4', '/content/drive/MyDrive/Face_only_data/alvgwypubw.mp4', '/content/drive/MyDrive/Face_only_data/aknmpoonls.mp4', '/content/drive/MyDrive/Face_only_data/akxoopqjqz.mp4', '/content/drive/MyDrive/Face_only_data/alninxcyhg.mp4', '/content/drive/MyDrive/Face_only_data/alaijyygdv.mp4', '/content/drive/MyDrive/Face_only_data/altziddtxi.mp4', '/content/drive/MyDrive/Face_only_data/akzbnazxtz.mp4', '/content/drive/MyDrive/Face_only_data/aqpnvjhuzw.mp4', '/content/drive/MyDrive/Face_only_data/amowujxmzc.mp4', '/content/drive/MyDrive/Face_only_data/apatcsqejh.mp4', '/content/drive/MyDrive/Face_only_data/anpuvshzoo.mp4', '/content/drive/MyDrive/Face_only_data/apgjqzkoma.mp4', '/content/drive/MyDrive/Face_only_data/aneclqfpbt.mp4', '/content/drive/MyDrive/Face_only_data/apogckdfrz.mp4', '/content/drive/MyDrive/Face_only_data/aslsvlvpth.mp4', '/content/drive/MyDrive/Face_only_data/asmpfjfzif.mp4', '/content/drive/MyDrive/Face_only_data/asvcrfdpnq.mp4', '/content/drive/MyDrive/Face_only_data/asdpeebotb.mp4', '/content/drive/MyDrive/Face_only_data/arkroixhey.mp4', '/content/drive/MyDrive/Face_only_data/arlmiizoob.mp4', '/content/drive/MyDrive/Face_only_data/arrhsnjqku.mp4', '/content/drive/MyDrive/Face_only_data/atkdltyyen.mp4', '/content/drive/MyDrive/Face_only_data/asaxgevnnp.mp4', '/content/drive/MyDrive/Face_only_data/atxvxouljq.mp4', '/content/drive/MyDrive/Face_only_data/avfitoutyn.mp4', '/content/drive/MyDrive/Face_only_data/atzdznmder.mp4', '/content/drive/MyDrive/Face_only_data/aufmsmnoye.mp4', '/content/drive/MyDrive/Face_only_data/avgiuextiz.mp4', '/content/drive/MyDrive/Face_only_data/avnqydkqjj.mp4', '/content/drive/MyDrive/Face_only_data/atyntldecu.mp4', '/content/drive/MyDrive/Face_only_data/avssvvsdhz.mp4', '/content/drive/MyDrive/Face_only_data/avtycwsgyb.mp4', '/content/drive/MyDrive/Face_only_data/avmjormvsx.mp4', '/content/drive/MyDrive/Face_only_data/awhmfnnjih.mp4', '/content/drive/MyDrive/Face_only_data/awukslzjra.mp4', '/content/drive/MyDrive/Face_only_data/avywawptfc.mp4', '/content/drive/MyDrive/Face_only_data/awnwkrqibf.mp4', '/content/drive/MyDrive/Face_only_data/avibnnhwhp.mp4', '/content/drive/MyDrive/Face_only_data/axwovszumc.mp4', '/content/drive/MyDrive/Face_only_data/aybumesmpk.mp4', '/content/drive/MyDrive/Face_only_data/aybgughjxh.mp4', '/content/drive/MyDrive/Face_only_data/axoygtekut.mp4', '/content/drive/MyDrive/Face_only_data/axntxmycwd.mp4', '/content/drive/MyDrive/Face_only_data/axczxisdtb.mp4', '/content/drive/MyDrive/Face_only_data/bchnbulevv.mp4', '/content/drive/MyDrive/Face_only_data/ayqvfdhslr.mp4', '/content/drive/MyDrive/Face_only_data/aytzyidmgs.mp4', '/content/drive/MyDrive/Face_only_data/bbhpvrmbse.mp4', '/content/drive/MyDrive/Face_only_data/azsmewqghg.mp4', '/content/drive/MyDrive/Face_only_data/azpuxunqyo.mp4', '/content/drive/MyDrive/Face_only_data/bahdpoesir.mp4', '/content/drive/MyDrive/Face_only_data/bbhtdfuqxq.mp4', '/content/drive/MyDrive/Face_only_data/bctvsmddgq.mp4', '/content/drive/MyDrive/Face_only_data/bdbhekrrwo.mp4', '/content/drive/MyDrive/Face_only_data/beboztfcme.mp4', '/content/drive/MyDrive/Face_only_data/bdgipnyobr.mp4', '/content/drive/MyDrive/Face_only_data/bdxuhamuqx.mp4', '/content/drive/MyDrive/Face_only_data/bejhvclboh.mp4', '/content/drive/MyDrive/Face_only_data/benmsfzfaz.mp4', '/content/drive/MyDrive/Face_only_data/bddjdhzfze.mp4', '/content/drive/MyDrive/Face_only_data/bdnaqemxmr.mp4', '/content/drive/MyDrive/Face_only_data/bhsluedavd.mp4', '/content/drive/MyDrive/Face_only_data/bhpwpydzpo.mp4', '/content/drive/MyDrive/Face_only_data/bhaaboftbc.mp4', '/content/drive/MyDrive/Face_only_data/bguwlyazau.mp4', '/content/drive/MyDrive/Face_only_data/bffwsjxghk.mp4', '/content/drive/MyDrive/Face_only_data/beyebyhrph.mp4', '/content/drive/MyDrive/Face_only_data/bggsurpgpr.mp4', '/content/drive/MyDrive/Face_only_data/bhbdugnurr.mp4', '/content/drive/MyDrive/Face_only_data/bgwmmujlmc.mp4', '/content/drive/MyDrive/Face_only_data/bgaogsjehq.mp4', '/content/drive/MyDrive/Face_only_data/bgmlwsoamc.mp4', '/content/drive/MyDrive/Face_only_data/bgvhtpzknn.mp4', '/content/drive/MyDrive/Face_only_data/bghphrsfxf.mp4', '/content/drive/MyDrive/Face_only_data/bjkmjilrxp.mp4', '/content/drive/MyDrive/Face_only_data/bmjzrlszhi.mp4', '/content/drive/MyDrive/Face_only_data/bkvetcojbt.mp4', '/content/drive/MyDrive/Face_only_data/bmioepcpsx.mp4', '/content/drive/MyDrive/Face_only_data/bjjbwsqjir.mp4', '/content/drive/MyDrive/Face_only_data/blpchvmhxx.mp4', '/content/drive/MyDrive/Face_only_data/bmehkyanbj.mp4', '/content/drive/MyDrive/Face_only_data/bmbbkwmxqj.mp4', '/content/drive/MyDrive/Face_only_data/blzydqdfem.mp4', '/content/drive/MyDrive/Face_only_data/bilnggbxgu.mp4', '/content/drive/MyDrive/Face_only_data/bmhvktyiwp.mp4', '/content/drive/MyDrive/Face_only_data/bjsmaqefoi.mp4', '/content/drive/MyDrive/Face_only_data/bmjmjmbglm.mp4', '/content/drive/MyDrive/Face_only_data/bkwxhglwct.mp4', '/content/drive/MyDrive/Face_only_data/bkmdzhfzfh.mp4', '/content/drive/MyDrive/Face_only_data/bnbuonyoje.mp4', '/content/drive/MyDrive/Face_only_data/bndybcqhfr.mp4', '/content/drive/MyDrive/Face_only_data/bpxckdzddv.mp4', '/content/drive/MyDrive/Face_only_data/bopqhhalml.mp4', '/content/drive/MyDrive/Face_only_data/bqtuuwzdtr.mp4', '/content/drive/MyDrive/Face_only_data/bpwzipqtxf.mp4', '/content/drive/MyDrive/Face_only_data/bqhtpqmmqp.mp4', '/content/drive/MyDrive/Face_only_data/bntlodcfeg.mp4', '/content/drive/MyDrive/Face_only_data/bqeiblbxtl.mp4', '/content/drive/MyDrive/Face_only_data/bqqpbzjgup.mp4', '/content/drive/MyDrive/Face_only_data/bqnymlsayl.mp4', '/content/drive/MyDrive/Face_only_data/bpapbctoao.mp4', '/content/drive/MyDrive/Face_only_data/bofqajtwve.mp4', '/content/drive/MyDrive/Face_only_data/bourlmzsio.mp4', '/content/drive/MyDrive/Face_only_data/bnjcdrfuov.mp4', '/content/drive/MyDrive/Face_only_data/boovltmuwi.mp4', '/content/drive/MyDrive/Face_only_data/bqdjzqhcft.mp4', '/content/drive/MyDrive/Face_only_data/btmsngnqhv.mp4', '/content/drive/MyDrive/Face_only_data/btunxncpjh.mp4', '/content/drive/MyDrive/Face_only_data/bseamdrpbj.mp4', '/content/drive/MyDrive/Face_only_data/btohlidmru.mp4', '/content/drive/MyDrive/Face_only_data/btjwbtsgln.mp4', '/content/drive/MyDrive/Face_only_data/btiysiskpf.mp4', '/content/drive/MyDrive/Face_only_data/btjlfpzbdu.mp4', '/content/drive/MyDrive/Face_only_data/brhalypwoo.mp4', '/content/drive/MyDrive/Face_only_data/brwrlczjvi.mp4', '/content/drive/MyDrive/Face_only_data/btugrnoton.mp4', '/content/drive/MyDrive/Face_only_data/brvqtabyxj.mp4', '/content/drive/MyDrive/Face_only_data/bsqgziaylx.mp4', '/content/drive/MyDrive/Face_only_data/bsfmwclnqy.mp4', '/content/drive/MyDrive/Face_only_data/bwuwstvsbw.mp4', '/content/drive/MyDrive/Face_only_data/btxlttbpkj.mp4', '/content/drive/MyDrive/Face_only_data/bwhlgysghg.mp4', '/content/drive/MyDrive/Face_only_data/bvgwelbeof.mp4', '/content/drive/MyDrive/Face_only_data/byofowlkki.mp4', '/content/drive/MyDrive/Face_only_data/bydaidkpdp.mp4', '/content/drive/MyDrive/Face_only_data/bulkxhhknf.mp4', '/content/drive/MyDrive/Face_only_data/byfenovjnf.mp4', '/content/drive/MyDrive/Face_only_data/bwipwzzxxu.mp4', '/content/drive/MyDrive/Face_only_data/bxzakyopjf.mp4', '/content/drive/MyDrive/Face_only_data/byijojkdba.mp4', '/content/drive/MyDrive/Face_only_data/bweezhfpzp.mp4', '/content/drive/MyDrive/Face_only_data/bvzjkezkms.mp4', '/content/drive/MyDrive/Face_only_data/byqzyxifza.mp4', '/content/drive/MyDrive/Face_only_data/ccmonzqfrz.mp4', '/content/drive/MyDrive/Face_only_data/caqbrkogkb.mp4', '/content/drive/MyDrive/Face_only_data/byunigvnay.mp4', '/content/drive/MyDrive/Face_only_data/cdbsbdymzd.mp4', '/content/drive/MyDrive/Face_only_data/cdaxixbosp.mp4', '/content/drive/MyDrive/Face_only_data/bzmdrafeex.mp4', '/content/drive/MyDrive/Face_only_data/bzythlfnhq.mp4', '/content/drive/MyDrive/Face_only_data/cbltdtxglo.mp4', '/content/drive/MyDrive/Face_only_data/caifxvsozs.mp4', '/content/drive/MyDrive/Face_only_data/ccfoszqabv.mp4', '/content/drive/MyDrive/Face_only_data/cbbibzcoih.mp4', '/content/drive/MyDrive/Face_only_data/byyqectxqa.mp4', '/content/drive/MyDrive/Face_only_data/cdphtzqrvp.mp4', '/content/drive/MyDrive/Face_only_data/cfyduhpbps.mp4', '/content/drive/MyDrive/Face_only_data/chtapglbcj.mp4', '/content/drive/MyDrive/Face_only_data/cferslmfwh.mp4', '/content/drive/MyDrive/Face_only_data/chzieimrwu.mp4', '/content/drive/MyDrive/Face_only_data/cepxysienc.mp4', '/content/drive/MyDrive/Face_only_data/cettndmvzl.mp4', '/content/drive/MyDrive/Face_only_data/cfxkpiweqt.mp4', '/content/drive/MyDrive/Face_only_data/cglxirfaey.mp4', '/content/drive/MyDrive/Face_only_data/chviwxsfhg.mp4', '/content/drive/MyDrive/Face_only_data/ceymbecxnj.mp4', '/content/drive/MyDrive/Face_only_data/cffffbcywc.mp4', '/content/drive/MyDrive/Face_only_data/cgvrgibpfo.mp4', '/content/drive/MyDrive/Face_only_data/cksanfsjhc.mp4', '/content/drive/MyDrive/Face_only_data/clihsshdkq.mp4', '/content/drive/MyDrive/Face_only_data/clrycekyst.mp4', '/content/drive/MyDrive/Face_only_data/ckbdwedgmc.mp4', '/content/drive/MyDrive/Face_only_data/covdcysmbi.mp4', '/content/drive/MyDrive/Face_only_data/cobjrlugvp.mp4', '/content/drive/MyDrive/Face_only_data/cpjxareypw.mp4', '/content/drive/MyDrive/Face_only_data/cmxcfkrjiv.mp4', '/content/drive/MyDrive/Face_only_data/ciyoudyhly.mp4', '/content/drive/MyDrive/Face_only_data/ckjaibzfxa.mp4', '/content/drive/MyDrive/Face_only_data/ckkuyewywx.mp4', '/content/drive/MyDrive/Face_only_data/cizlkenljw.mp4', '/content/drive/MyDrive/Face_only_data/cnilkgvfei.mp4', '/content/drive/MyDrive/Face_only_data/coadfnerlk.mp4', '/content/drive/MyDrive/Face_only_data/cknyxaqouy.mp4', '/content/drive/MyDrive/Face_only_data/cmbzllswnl.mp4', '/content/drive/MyDrive/Face_only_data/crktehraph.mp4', '/content/drive/MyDrive/Face_only_data/ctpqeykqdp.mp4', '/content/drive/MyDrive/Face_only_data/curpwogllm.mp4', '/content/drive/MyDrive/Face_only_data/cthdnahrkh.mp4', '/content/drive/MyDrive/Face_only_data/crzfebnfgb.mp4', '/content/drive/MyDrive/Face_only_data/ctzmavwror.mp4', '/content/drive/MyDrive/Face_only_data/cuzrgrbvil.mp4', '/content/drive/MyDrive/Face_only_data/cqhngvpgyi.mp4', '/content/drive/MyDrive/Face_only_data/crezycjqyk.mp4', '/content/drive/MyDrive/Face_only_data/cprhtltsjp.mp4', '/content/drive/MyDrive/Face_only_data/cqrskwiqng.mp4', '/content/drive/MyDrive/Face_only_data/cqfugiqupm.mp4', '/content/drive/MyDrive/Face_only_data/cttqtsjvgn.mp4', '/content/drive/MyDrive/Face_only_data/cppdvdejkc.mp4', '/content/drive/MyDrive/Face_only_data/cxttmymlbn.mp4', '/content/drive/MyDrive/Face_only_data/cxfujlvsuw.mp4', '/content/drive/MyDrive/Face_only_data/cwrtyzndpx.mp4', '/content/drive/MyDrive/Face_only_data/cvaksbpssm.mp4', '/content/drive/MyDrive/Face_only_data/cwsbspfzck.mp4', '/content/drive/MyDrive/Face_only_data/czfunozvwp.mp4', '/content/drive/MyDrive/Face_only_data/cyboodqqyr.mp4', '/content/drive/MyDrive/Face_only_data/cyclgfjdrv.mp4', '/content/drive/MyDrive/Face_only_data/cxrfacemmq.mp4', '/content/drive/MyDrive/Face_only_data/czkdanyadc.mp4', '/content/drive/MyDrive/Face_only_data/cwbacdwrzo.mp4', '/content/drive/MyDrive/Face_only_data/cyxlcuyznd.mp4', '/content/drive/MyDrive/Face_only_data/cwwandrkus.mp4', '/content/drive/MyDrive/Face_only_data/dbnygxtwek.mp4', '/content/drive/MyDrive/Face_only_data/dbtbbhakdv.mp4', '/content/drive/MyDrive/Face_only_data/ddjggcasdw.mp4', '/content/drive/MyDrive/Face_only_data/ddpvuimigj.mp4', '/content/drive/MyDrive/Face_only_data/dcamvmuors.mp4', '/content/drive/MyDrive/Face_only_data/dbzpcjntve.mp4', '/content/drive/MyDrive/Face_only_data/dbzcqmxzaj.mp4', '/content/drive/MyDrive/Face_only_data/dakqwktlbi.mp4', '/content/drive/MyDrive/Face_only_data/dbhrpizyeq.mp4', '/content/drive/MyDrive/Face_only_data/ddhfabwpuz.mp4', '/content/drive/MyDrive/Face_only_data/ddepeddixj.mp4', '/content/drive/MyDrive/Face_only_data/dakiztgtnw.mp4', '/content/drive/MyDrive/Face_only_data/dcuiiorugd.mp4', '/content/drive/MyDrive/Face_only_data/dbhoxkblzx.mp4', '/content/drive/MyDrive/Face_only_data/dboxtiehng.mp4', '/content/drive/MyDrive/Face_only_data/dafhtipaml.mp4', '/content/drive/MyDrive/Face_only_data/ddqccgmtka.mp4', '/content/drive/MyDrive/Face_only_data/dhjmzhrcav.mp4', '/content/drive/MyDrive/Face_only_data/dgmevclvzy.mp4', '/content/drive/MyDrive/Face_only_data/dgxrqjdomn.mp4', '/content/drive/MyDrive/Face_only_data/dhkwmjxwrn.mp4', '/content/drive/MyDrive/Face_only_data/degpbqvcay.mp4', '/content/drive/MyDrive/Face_only_data/dhevettufk.mp4', '/content/drive/MyDrive/Face_only_data/deywhkarol.mp4', '/content/drive/MyDrive/Face_only_data/dfbpceeaox.mp4', '/content/drive/MyDrive/Face_only_data/dhcselezer.mp4', '/content/drive/MyDrive/Face_only_data/deyyistcrd.mp4', '/content/drive/MyDrive/Face_only_data/dgzklxjmix.mp4', '/content/drive/MyDrive/Face_only_data/diuzrpqjli.mp4', '/content/drive/MyDrive/Face_only_data/dhcndnuwta.mp4', '/content/drive/MyDrive/Face_only_data/diqraixiov.mp4', '/content/drive/MyDrive/Face_only_data/diopzaywor.mp4', '/content/drive/MyDrive/Face_only_data/dkuayagnmc.mp4', '/content/drive/MyDrive/Face_only_data/djxdyjopjd.mp4', '/content/drive/MyDrive/Face_only_data/diomeixhrg.mp4', '/content/drive/MyDrive/Face_only_data/dkdwxmtpuo.mp4', '/content/drive/MyDrive/Face_only_data/djvtbgwdcc.mp4', '/content/drive/MyDrive/Face_only_data/dhxctgyoqj.mp4', '/content/drive/MyDrive/Face_only_data/dkrvorliqc.mp4', '/content/drive/MyDrive/Face_only_data/dkwjwbwgey.mp4', '/content/drive/MyDrive/Face_only_data/dptrzdvwpg.mp4', '/content/drive/MyDrive/Face_only_data/dofusvhnib.mp4', '/content/drive/MyDrive/Face_only_data/dqqtjcryjv.mp4', '/content/drive/MyDrive/Face_only_data/dozyddhild.mp4', '/content/drive/MyDrive/Face_only_data/dnexlwbcxq.mp4', '/content/drive/MyDrive/Face_only_data/dnyvfblxpm.mp4', '/content/drive/MyDrive/Face_only_data/dntkzzzcdh.mp4', '/content/drive/MyDrive/Face_only_data/dlrsbscitn.mp4', '/content/drive/MyDrive/Face_only_data/dkzvdrzcnr.mp4', '/content/drive/MyDrive/Face_only_data/doanjploai.mp4', '/content/drive/MyDrive/Face_only_data/dqppxmoqdl.mp4', '/content/drive/MyDrive/Face_only_data/dlpoieqvfb.mp4', '/content/drive/MyDrive/Face_only_data/dptbnjnkdg.mp4', '/content/drive/MyDrive/Face_only_data/dqswpjoepo.mp4', '/content/drive/MyDrive/Face_only_data/dqzreruvje.mp4', '/content/drive/MyDrive/Face_only_data/dulanfulol.mp4', '/content/drive/MyDrive/Face_only_data/duvyaxbzvp.mp4', '/content/drive/MyDrive/Face_only_data/drcyabprvt.mp4', '/content/drive/MyDrive/Face_only_data/dsdoseflas.mp4', '/content/drive/MyDrive/Face_only_data/dsjbknkujw.mp4', '/content/drive/MyDrive/Face_only_data/dubiroskqn.mp4', '/content/drive/MyDrive/Face_only_data/drsakwyvqv.mp4', '/content/drive/MyDrive/Face_only_data/drtbksnpol.mp4', '/content/drive/MyDrive/Face_only_data/dtbpmdqvao.mp4', '/content/drive/MyDrive/Face_only_data/dtocdfbwca.mp4', '/content/drive/MyDrive/Face_only_data/drgjzlxzxj.mp4', '/content/drive/MyDrive/Face_only_data/dsndhujjjb.mp4', '/content/drive/MyDrive/Face_only_data/dsgpbgsrdm.mp4', '/content/drive/MyDrive/Face_only_data/dzwkmcwkwl.mp4', '/content/drive/MyDrive/Face_only_data/eahlqmfvtj.mp4', '/content/drive/MyDrive/Face_only_data/dwediigjit.mp4', '/content/drive/MyDrive/Face_only_data/eajlrktemq.mp4', '/content/drive/MyDrive/Face_only_data/dxuliowugt.mp4', '/content/drive/MyDrive/Face_only_data/duzuusuajr.mp4', '/content/drive/MyDrive/Face_only_data/dzvyfiarrq.mp4', '/content/drive/MyDrive/Face_only_data/dvumqqhoac.mp4', '/content/drive/MyDrive/Face_only_data/ebchwmwayp.mp4', '/content/drive/MyDrive/Face_only_data/dvakowbgbt.mp4', '/content/drive/MyDrive/Face_only_data/dzyuwjkjui.mp4', '/content/drive/MyDrive/Face_only_data/dzqwgqewhu.mp4', '/content/drive/MyDrive/Face_only_data/dxbqjxrhin.mp4', '/content/drive/MyDrive/Face_only_data/dxuplhwvig.mp4', '/content/drive/MyDrive/Face_only_data/dzieklokdr.mp4', '/content/drive/MyDrive/Face_only_data/duycddgtrl.mp4', '/content/drive/MyDrive/Face_only_data/edyncaijwx.mp4', '/content/drive/MyDrive/Face_only_data/eebrkicpry.mp4', '/content/drive/MyDrive/Face_only_data/ebeknhudxq.mp4', '/content/drive/MyDrive/Face_only_data/ecnihjlfyt.mp4', '/content/drive/MyDrive/Face_only_data/ebebgmtlcu.mp4', '/content/drive/MyDrive/Face_only_data/eebserckhh.mp4', '/content/drive/MyDrive/Face_only_data/ecwaxgutkc.mp4', '/content/drive/MyDrive/Face_only_data/ecujsjhscd.mp4', '/content/drive/MyDrive/Face_only_data/ebywfrmhtd.mp4', '/content/drive/MyDrive/Face_only_data/eekozbeafq.mp4', '/content/drive/MyDrive/Face_only_data/eckvhdusax.mp4', '/content/drive/MyDrive/Face_only_data/ebkzwjgjhq.mp4', '/content/drive/MyDrive/Face_only_data/eejswgycjc.mp4', '/content/drive/MyDrive/Face_only_data/ecuvtoltue.mp4', '/content/drive/MyDrive/Face_only_data/eczrseixwq.mp4', '/content/drive/MyDrive/Face_only_data/ehieahnhte.mp4', '/content/drive/MyDrive/Face_only_data/ehdkmxgtxh.mp4', '/content/drive/MyDrive/Face_only_data/ehccixxzoe.mp4', '/content/drive/MyDrive/Face_only_data/efdyrflcpg.mp4', '/content/drive/MyDrive/Face_only_data/ehbnclaukr.mp4', '/content/drive/MyDrive/Face_only_data/ehevsxtecd.mp4', '/content/drive/MyDrive/Face_only_data/egbbcxcuqy.mp4', '/content/drive/MyDrive/Face_only_data/egghxjjmfg.mp4', '/content/drive/MyDrive/Face_only_data/eiriyukqqy.mp4', '/content/drive/MyDrive/Face_only_data/eggbjzxnmg.mp4', '/content/drive/MyDrive/Face_only_data/ehtdtkmmli.mp4', '/content/drive/MyDrive/Face_only_data/eepezmygaq.mp4', '/content/drive/MyDrive/Face_only_data/eeyhxisdfh.mp4', '/content/drive/MyDrive/Face_only_data/emaalmsonj.mp4', '/content/drive/MyDrive/Face_only_data/efwfxwwlbw.mp4', '/content/drive/MyDrive/Face_only_data/ejkqesyvam.mp4', '/content/drive/MyDrive/Face_only_data/eixwxvxbbn.mp4', '/content/drive/MyDrive/Face_only_data/ekhacizpah.mp4', '/content/drive/MyDrive/Face_only_data/ekcrtigpab.mp4', '/content/drive/MyDrive/Face_only_data/elvvackpjh.mp4', '/content/drive/MyDrive/Face_only_data/emfbhytfhc.mp4', '/content/drive/MyDrive/Face_only_data/eiwopxzjfn.mp4', '/content/drive/MyDrive/Face_only_data/ensyyivobf.mp4', '/content/drive/MyDrive/Face_only_data/elginszwtk.mp4', '/content/drive/MyDrive/Face_only_data/eivxffliio.mp4', '/content/drive/MyDrive/Face_only_data/ekkdjkirzq.mp4', '/content/drive/MyDrive/Face_only_data/emgjphonqb.mp4', '/content/drive/MyDrive/Face_only_data/ellavthztb.mp4', '/content/drive/MyDrive/Face_only_data/eprybmbpba.mp4', '/content/drive/MyDrive/Face_only_data/eqnoqyfquo.mp4', '/content/drive/MyDrive/Face_only_data/eqjscdagiv.mp4', '/content/drive/MyDrive/Face_only_data/esxrvsgpvb.mp4', '/content/drive/MyDrive/Face_only_data/esnntzzajv.mp4', '/content/drive/MyDrive/Face_only_data/errocgcham.mp4', '/content/drive/MyDrive/Face_only_data/erqgqacbqe.mp4', '/content/drive/MyDrive/Face_only_data/etdcqxabww.mp4', '/content/drive/MyDrive/Face_only_data/etejaapnxh.mp4', '/content/drive/MyDrive/Face_only_data/esgftaficx.mp4', '/content/drive/MyDrive/Face_only_data/esckbnkkvb.mp4', '/content/drive/MyDrive/Face_only_data/etmcruaihe.mp4', '/content/drive/MyDrive/Face_only_data/eqvuznuwsa.mp4', '/content/drive/MyDrive/Face_only_data/erlvuvjsjf.mp4', '/content/drive/MyDrive/Face_only_data/eudeqjhdfd.mp4', '/content/drive/MyDrive/Face_only_data/esyrimvzsa.mp4', '/content/drive/MyDrive/Face_only_data/etohcvnzbj.mp4', '/content/drive/MyDrive/Face_only_data/eukvucdetx.mp4']\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import copy\n",
        "import random\n",
        "video_files =  glob.glob('/content/drive/MyDrive/Face_only_data/*.mp4')\n",
        "random.shuffle(video_files)\n",
        "random.shuffle(video_files)\n",
        "frame_count = []\n",
        "for video_file in video_files:\n",
        "  cap = cv2.VideoCapture(video_file)\n",
        "  if(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))<100):\n",
        "    video_files.remove(video_file)\n",
        "    continue\n",
        "  frame_count.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
        "print(\"frames are \" , frame_count)\n",
        "print(\"Total no of video: \" , len(frame_count))\n",
        "print('Average frame per video:',np.mean(frame_count))"
      ],
      "metadata": {
        "id": "wlaIK8jWkFXG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e6c254a-3b5b-49f2-cfbc-d0a820e34947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "frames are  [148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 128, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 142, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 144, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148]\n",
            "Total no of video:  372\n",
            "Average frame per video: 147.91935483870967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the video name and labels from csv\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import face_recognition\n",
        "class video_dataset(Dataset):\n",
        "    def __init__(self,video_names,labels,sequence_length = 60,transform = None):\n",
        "        self.video_names = video_names\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        self.count = sequence_length\n",
        "    def __len__(self):\n",
        "        return len(self.video_names)\n",
        "    def __getitem__(self,idx):\n",
        "        video_path = self.video_names[idx]\n",
        "        frames = []\n",
        "        a = int(100/self.count)\n",
        "        first_frame = np.random.randint(0,a)\n",
        "        temp_video = video_path.split('/')[-1]\n",
        "        #print(temp_video)\n",
        "        label = self.labels.iloc[(labels.loc[labels[\"file\"] == temp_video].index.values[0]),1]\n",
        "        if(label == 'FAKE'):\n",
        "          label = 0\n",
        "        if(label == 'REAL'):\n",
        "          label = 1\n",
        "        for i,frame in enumerate(self.frame_extract(video_path)):\n",
        "          frames.append(self.transform(frame))\n",
        "          if(len(frames) == self.count):\n",
        "            break\n",
        "        frames = torch.stack(frames)\n",
        "        frames = frames[:self.count]\n",
        "        #print(\"length:\" , len(frames), \"label\",label)\n",
        "        return frames,label\n",
        "    def frame_extract(self,path):\n",
        "      vidObj = cv2.VideoCapture(path)\n",
        "      success = 1\n",
        "      while success:\n",
        "          success, image = vidObj.read()\n",
        "          if success:\n",
        "              yield image\n",
        "#plot the image\n",
        "def im_plot(tensor):\n",
        "    image = tensor.cpu().numpy().transpose(1,2,0)\n",
        "    b,g,r = cv2.split(image)\n",
        "    image = cv2.merge((r,g,b))\n",
        "    image = image*[0.22803, 0.22145, 0.216989] +  [0.43216, 0.394666, 0.37645]\n",
        "    image = image*255.0\n",
        "    plt.imshow(image.astype(int))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "57PlsY8R3L3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#count the number of fake and real videos\n",
        "def number_of_real_and_fake_videos(data_list):\n",
        "  header_list = [\"file\",\"label\"]\n",
        "  lab = pd.read_csv('/content/drive/My Drive/Gobal_metadata.csv',names=header_list)\n",
        "  fake = 0\n",
        "  real = 0\n",
        "  for i in data_list:\n",
        "    temp_video = i.split('/')[-1]\n",
        "    label = lab.iloc[(labels.loc[labels[\"file\"] == temp_video].index.values[0]),1]\n",
        "    if(label == 'FAKE'):\n",
        "      fake+=1\n",
        "    if(label == 'REAL'):\n",
        "      real+=1\n",
        "\n",
        "  return real,fake"
      ],
      "metadata": {
        "id": "FWntpSYb3pVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the labels and video in data loader\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "header_list = [\"file\",\"label\"]\n",
        "labels = pd.read_csv('/content/drive/My Drive/Gobal_metadata.csv',names=header_list)\n",
        "#print(labels)\n",
        "train_videos = video_files[:int(0.8*len(video_files))]\n",
        "valid_videos = video_files[int(0.8*len(video_files)):]\n",
        "print(\"train : \" , len(train_videos))\n",
        "print(\"test : \" , len(valid_videos))\n",
        "\n",
        "print(\"TRAIN: \", \"Real:\",number_of_real_and_fake_videos(train_videos)[0],\" Fake:\",number_of_real_and_fake_videos(train_videos)[1])\n",
        "print(\"TEST: \", \"Real:\",number_of_real_and_fake_videos(valid_videos)[0],\" Fake:\",number_of_real_and_fake_videos(valid_videos)[1])\n",
        "\n",
        "\n",
        "im_size = 112\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "                                        transforms.ToPILImage(),\n",
        "                                        transforms.Resize((im_size,im_size)),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean,std)])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "                                        transforms.ToPILImage(),\n",
        "                                        transforms.Resize((im_size,im_size)),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean,std)])\n",
        "train_data = video_dataset(train_videos,labels,sequence_length = 10,transform = train_transforms)\n",
        "#print(train_data)\n",
        "val_data = video_dataset(valid_videos,labels,sequence_length = 10,transform = train_transforms)\n",
        "train_loader = DataLoader(train_data,batch_size = 4,shuffle = True,num_workers = 4)\n",
        "valid_loader = DataLoader(val_data,batch_size = 4,shuffle = True,num_workers = 4)\n",
        "image,label = train_data[0]\n",
        "im_plot(image[0,:,:,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "duTgFmoU4G0q",
        "outputId": "503e5289-7649-429e-e029-38db7f8cef89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train :  299\n",
            "test :  75\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 0 is out of bounds for axis 0 with size 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-31a154e9dea9>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test : \"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_videos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TRAIN: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Real:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumber_of_real_and_fake_videos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_videos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" Fake:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumber_of_real_and_fake_videos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_videos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TEST: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Real:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumber_of_real_and_fake_videos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_videos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" Fake:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumber_of_real_and_fake_videos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_videos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-9af6873a2f75>\u001b[0m in \u001b[0;36mnumber_of_real_and_fake_videos\u001b[0;34m(data_list)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtemp_video\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"file\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtemp_video\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'FAKE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mfake\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torchvision import models\n",
        "import torch\n",
        "\n",
        "class CBAM(nn.Module):\n",
        "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max']):\n",
        "        super(CBAM, self).__init__()\n",
        "        self.gate_channels = gate_channels\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(gate_channels, gate_channels // reduction_ratio),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(gate_channels // reduction_ratio, gate_channels)\n",
        "        )\n",
        "        self.pool_types = pool_types\n",
        "\n",
        "    def forward(self, x):\n",
        "        channel_att_raw = self.mlp(torch.cat([torch.mean(x, dim=(2, 3)), torch.max(x, dim=(2, 3))[0]], dim=1))\n",
        "        scale = torch.sigmoid(channel_att_raw).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
        "        for pool in self.pool_types:\n",
        "            if pool == 'avg':\n",
        "                spatial_att_raw = torch.mean(x, dim=1, keepdim=True)\n",
        "            elif pool == 'max':\n",
        "                spatial_att_raw, _ = torch.max(x, dim=1, keepdim=True)\n",
        "            spatial_att = torch.sigmoid(spatial_att_raw)\n",
        "            x = x * spatial_att * scale\n",
        "        return x\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, num_classes, latent_dim=2048, lstm_layers=1, hidden_dim=2048, bidirectional=False):\n",
        "        super(Model, self).__init__()\n",
        "        model = models.resnext50_32x4d(pretrained=True)  # Residual Network CNN\n",
        "        self.model = nn.Sequential(*list(model.children())[:-2])\n",
        "        self.cbam = CBAM(latent_dim)\n",
        "        self.lstm = nn.LSTM(latent_dim, hidden_dim, lstm_layers, bidirectional)\n",
        "        self.relu = nn.LeakyReLU()\n",
        "        self.dp = nn.Dropout(0.4)\n",
        "        self.linear1 = nn.Linear(2048, num_classes)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_length, c, h, w = x.shape\n",
        "        x = x.view(batch_size * seq_length, c, h, w)\n",
        "        fmap = self.model(x)\n",
        "        x = self.avgpool(fmap)\n",
        "        x = self.cbam(x)\n",
        "        x = x.view(batch_size, seq_length, 2048)\n",
        "        x_lstm, _ = self.lstm(x, None)\n",
        "        return fmap, self.dp(self.linear1(torch.mean(x_lstm, dim=1)))"
      ],
      "metadata": {
        "id": "neIuAozEsaMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Model(2).cuda()\n",
        "a,b = model(torch.from_numpy(np.empty((1,20,3,112,112))).type(torch.cuda.FloatTensor))\n"
      ],
      "metadata": {
        "id": "SsNrChQSe11Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "import os\n",
        "def train_epoch(epoch, num_epochs, data_loader, model, criterion, optimizer):\n",
        "    model.train()\n",
        "    losses = AverageMeter()\n",
        "    accuracies = AverageMeter()\n",
        "    t = []\n",
        "    for i, (inputs, targets) in enumerate(data_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            targets = targets.type(torch.cuda.LongTensor)\n",
        "            inputs = inputs.cuda()\n",
        "        _,outputs = model(inputs)\n",
        "        loss  = criterion(outputs,targets.type(torch.cuda.LongTensor))\n",
        "        acc = calculate_accuracy(outputs, targets.type(torch.cuda.LongTensor))\n",
        "        losses.update(loss.item(), inputs.size(0))\n",
        "        accuracies.update(acc, inputs.size(0))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        sys.stdout.write(\n",
        "                \"\\r[Epoch %d/%d] [Batch %d / %d] [Loss: %f, Acc: %.2f%%]\"\n",
        "                % (\n",
        "                    epoch,\n",
        "                    num_epochs,\n",
        "                    i,\n",
        "                    len(data_loader),\n",
        "                    losses.avg,\n",
        "                    accuracies.avg))\n",
        "    torch.save(model.state_dict(),'/content/checkpoint.pt')\n",
        "    return losses.avg,accuracies.avg\n",
        "def test(epoch,model, data_loader ,criterion):\n",
        "    print('Testing')\n",
        "    model.eval()\n",
        "    losses = AverageMeter()\n",
        "    accuracies = AverageMeter()\n",
        "    pred = []\n",
        "    true = []\n",
        "    count = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, targets) in enumerate(data_loader):\n",
        "            if torch.cuda.is_available():\n",
        "                targets = targets.cuda().type(torch.cuda.FloatTensor)\n",
        "                inputs = inputs.cuda()\n",
        "            _,outputs = model(inputs)\n",
        "            loss = torch.mean(criterion(outputs, targets.type(torch.cuda.LongTensor)))\n",
        "            acc = calculate_accuracy(outputs,targets.type(torch.cuda.LongTensor))\n",
        "            _,p = torch.max(outputs,1)\n",
        "            true += (targets.type(torch.cuda.LongTensor)).detach().cpu().numpy().reshape(len(targets)).tolist()\n",
        "            pred += p.detach().cpu().numpy().reshape(len(p)).tolist()\n",
        "            losses.update(loss.item(), inputs.size(0))\n",
        "            accuracies.update(acc, inputs.size(0))\n",
        "            sys.stdout.write(\n",
        "                    \"\\r[Batch %d / %d]  [Loss: %f, Acc: %.2f%%]\"\n",
        "                    % (\n",
        "                        i,\n",
        "                        len(data_loader),\n",
        "                        losses.avg,\n",
        "                        accuracies.avg\n",
        "                        )\n",
        "                    )\n",
        "        print('\\nAccuracy {}'.format(accuracies.avg))\n",
        "    return true,pred,losses.avg,accuracies.avg\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "def calculate_accuracy(outputs, targets):\n",
        "    batch_size = targets.size(0)\n",
        "\n",
        "    _, pred = outputs.topk(1, 1, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(targets.view(1, -1))\n",
        "    n_correct_elems = correct.float().sum().item()\n",
        "    return 100* n_correct_elems / batch_size\n"
      ],
      "metadata": {
        "id": "kAJlNA4Ue9iL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sn\n",
        "#Output confusion matrix\n",
        "def print_confusion_matrix(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print('True positive = ', cm[0][0])\n",
        "    print('False positive = ', cm[0][1])\n",
        "    print('False negative = ', cm[1][0])\n",
        "    print('True negative = ', cm[1][1])\n",
        "    print('\\n')\n",
        "    df_cm = pd.DataFrame(cm, range(2), range(2))\n",
        "    sn.set(font_scale=1.4) # for label size\n",
        "    sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
        "    plt.ylabel('Actual label', size = 20)\n",
        "    plt.xlabel('Predicted label', size = 20)\n",
        "    plt.xticks(np.arange(2), ['Fake', 'Real'], size = 16)\n",
        "    plt.yticks(np.arange(2), ['Fake', 'Real'], size = 16)\n",
        "    plt.ylim([2, 0])\n",
        "    plt.show()\n",
        "    calculated_acc = (cm[0][0]+cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+ cm[1][1])\n",
        "    print(\"Calculated Accuracy\",calculated_acc*100)"
      ],
      "metadata": {
        "id": "Z8Mz2QMte-kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss(train_loss_avg,test_loss_avg,num_epochs):\n",
        "  loss_train = train_loss_avg\n",
        "  loss_val = test_loss_avg\n",
        "  print(num_epochs)\n",
        "  epochs = range(1,num_epochs+1)\n",
        "  plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "  plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
        "  plt.title('Training and Validation loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "def plot_accuracy(train_accuracy,test_accuracy,num_epochs):\n",
        "  loss_train = train_accuracy\n",
        "  loss_val = test_accuracy\n",
        "  epochs = range(1,num_epochs+1)\n",
        "  plt.plot(epochs, loss_train, 'g', label='Training accuracy')\n",
        "  plt.plot(epochs, loss_val, 'b', label='validation accuracy')\n",
        "  plt.title('Training and Validation accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "wXgV37mDfCN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "#learning rate\n",
        "lr = 1e-5#0.001\n",
        "#number of epochs\n",
        "num_epochs = 20\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr= lr,weight_decay = 1e-5)\n",
        "\n",
        "#class_weights = torch.from_numpy(np.asarray([1,15])).type(torch.FloatTensor).cuda()\n",
        "#criterion = nn.CrossEntropyLoss(weight = class_weights).cuda()\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "train_loss_avg =[]\n",
        "train_accuracy = []\n",
        "test_loss_avg = []\n",
        "test_accuracy = []\n",
        "for epoch in range(1,num_epochs+1):\n",
        "    l, acc = train_epoch(epoch,num_epochs,train_loader,model,criterion,optimizer)\n",
        "    train_loss_avg.append(l)\n",
        "    train_accuracy.append(acc)\n",
        "    true,pred,tl,t_acc = test(epoch,model,valid_loader,criterion)\n",
        "    test_loss_avg.append(tl)\n",
        "    test_accuracy.append(t_acc)\n",
        "plot_loss(train_loss_avg,test_loss_avg,len(train_loss_avg))\n",
        "plot_accuracy(train_accuracy,test_accuracy,len(train_accuracy))\n",
        "print(confusion_matrix(true,pred))\n",
        "print_confusion_matrix(true,pred)"
      ],
      "metadata": {
        "id": "U4-Q_x8zfFnx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}